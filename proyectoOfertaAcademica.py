# -*- coding: utf-8 -*-
"""ProyectoParcial2.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1nC3UmEEjsqSrkI5W7IZgsPL_AFKrP82-
"""

!pip install PdfReader
!pip install PyPDF2
from urllib import request
import re
import pandas as pd
from bs4 import BeautifulSoup
from PyPDF2 import PdfReader, PdfWriter

hdr = {'User-Agent': 'Wget/1.14 (linux-gnu)','Accept':'*/*'}
OfertaAcademica = {}
PaginaConahcyt = "https://centrosconahcyt.net/oferta-academica/"
PaginaTxt = BeautifulSoup(request.urlopen(request.Request(PaginaConahcyt, headers=hdr)).read().decode('utf8'), 'html.parser')
Carreras = PaginaTxt.find_all("div",{"class": "blog-masonry-item"})
for div in Carreras:
    Area = re.sub("\n", "", div.find(class_='post-meta').text)
    Sede = div.find('span').text
    OfertaAcademica[div.find('h4').text] = [Sede, Area]

del OfertaAcademica['Cursos - CIATEC']
del OfertaAcademica['CIATEQ']
del OfertaAcademica['GCI']
del OfertaAcademica['JUVE']

df = pd.DataFrame.from_dict(OfertaAcademica, orient='index', columns=['Sede', 'Área de Investigación'])
df.reset_index(inplace=True)
df.rename(columns={'index': 'Carrera'}, inplace=True)
df.to_excel('ofertaConahcyt.xlsx', index=False)

import numpy as np
from google.colab import autoviz

def categorical_histogram(df, colname, figscale=1, mpl_palette_name='Dark2'):
  from matplotlib import pyplot as plt
  import seaborn as sns
  df.groupby(colname).size().plot(kind='barh', color=sns.palettes.mpl_palette(mpl_palette_name), figsize=(8*figscale, 4.8*figscale))
  plt.gca().spines[['top', 'right',]].set_visible(False)
  return autoviz.MplChart.from_current_mpl_state()

chart = categorical_histogram(df, *['Área de Investigación'], **{})

df

chart

"""#2.- 5 escuelas publicas y 5 escuelas privadas

"""

# TEC DE MONTERREY
TEC = "https://maestriasydiplomados.tec.mx/programas/posgrados"
data = BeautifulSoup(request.urlopen(request.Request(TEC, headers=hdr)).read().decode('utf8'), 'html.parser')
CarrerasTEC = data.find_all("div",{"class": "newplcol"})
carrerasTECM = []
for div in CarrerasTEC:
    carrerasTECM.append(div.find('h3').text)
df1 = pd.DataFrame(carrerasTECM)
df1.columns = ["Carrera"]
df1.to_excel("ofertasTecDeMonterrey.xlsx", index=False)
df1

# escuela UNEDL
UNEDL = "https://www.unedl.edu.mx/posgrados/index.php?univ=unedl&tipoCarrera=3"
carrerasUNEDL = BeautifulSoup(request.urlopen(request.Request(UNEDL, headers=hdr)).read().decode('utf8'), 'html.parser').find_all("div",{"class": "col-md-4"})
carrerasUNEDL1 = []
for div in carrerasUNEDL:
    carrerasUNEDL1.append(div.find('h3').text)
df = pd.DataFrame(carrerasUNEDL1)
df.columns = ["Carrera"]
df.to_excel("ofertasUNEDL.xlsx", index=False)
df

# escuela ealde
ealde = "https://www.ealde.es/formacion/"
carrerasealde = BeautifulSoup(request.urlopen(request.Request(ealde, headers=hdr)).read().decode('utf8'), 'html.parser').find_all("li",{"class": "product"})
carrerasealde1 = []
for div in carrerasealde:
    carrerasealde1.append(div.find('h2').text)
df = pd.DataFrame(carrerasealde1)
df.columns = ["Carrera"]
df.to_excel("ofertasEALDE.xlsx", index=False)
df

# escuela ITESO
ITESO="https://posgrados.iteso.mx/"
data = BeautifulSoup(request.urlopen(request.Request(ITESO, headers=hdr)).read().decode('utf8'), 'html.parser')
CarreraITESO = data.find("div",{"id": "posgrados"})
format = r'(?:Maestría|Doctorado).*\<[s]'
CarreraITESO1 = re.findall(format, str(CarreraITESO))
CarreraITESO2 = []
for carrera in CarreraITESO1:
  CarreraITESO2.append(re.sub("\<s", "", carrera))
df = pd.DataFrame(CarreraITESO2)
df.columns = ["Carrera"]
df.to_excel("ofertaITESO.xlsx", index=False)
df

# escuela UAG
UAG="https://www.uag.mx/es/posgrados"
Data = BeautifulSoup(request.urlopen(request.Request(UAG, headers=hdr)).read().decode('utf8'), 'html.parser')
carrerasUAG = Data.find_all("div",{"class": "div25"})
carrerasUAG1 = []
for div in carrerasUAG:
    carreras_aux = div.find_all("div",{"class": "div100"})
    for aux in carreras_aux:
      carrera = re.findall(r'[A-Z]+.*', aux.text)
      if carrera not in carrerasUAG1:
        carrerasUAG1.append(carrera)
df = pd.DataFrame(carrerasUAG1, columns=["Carrera"])
df.to_excel("ofertaUAG.xlsx", index=False)
df

"""Publicas"""

# escuela UDG
UDG="https://www.udg.mx/es/oferta-academica/posgrados/maestrias"
data = BeautifulSoup( request.urlopen(request.Request(UDG, headers=hdr)).read().decode('utf8'), 'html.parser')
UDGCarreras = data.find_all("div",{"class": "views-row"})
UDGCarreras1 = []
for div in UDGCarreras:
    UDGCarreras1.append(re.findall(r'[A-Z]+.*',  div.find("span",{"class":'field-content'}).text))
df = pd.DataFrame(UDGCarreras1)
df.columns = ["Carrera"]
df.to_excel("ofertaUDG.xlsx", index=False)
df

# escuela UPN
UPN="https://upn.mx/index.php/estudiar-en-la-upn/posgrados"
data = BeautifulSoup(request.urlopen(request.Request(UPN, headers=hdr)).read().decode('utf8'), 'html.parser')
CarrerasUPN = data.find("div",{"itemprop": "articleBody"})
format = r'(?:Maestría|Doctorado|Especialización).*\<'
CarrerasUPN1 = re.findall(format, str(CarrerasUPN))
CarrerasUPN2 = []
for carrera in CarrerasUPN1:
  carrera = re.sub("</a><", "", carrera)
  CarrerasUPN2.append(carrera)
df = pd.DataFrame(CarrerasUPN2)
df.columns = ["Carrera"]
df.to_excel("ofertasUPN.xlsx", index=False)
df

#escuela UNAM
UNAM="https://www.posgrado.unam.mx/oferta-academica/maestria/"
data2 = BeautifulSoup(request.urlopen( request.Request(UNAM, headers=hdr)).read().decode('utf8'), 'html.parser')
UNAMCarreras = data2.find_all("div",{"class": "gdlr-core-course-item-list"})
carrerasUNAM = []
for div in UNAMCarreras:
    carrerasUNAM.append(div.find("span",{"class":'gdlr-core-course-item-title'}).text)
df2 = pd.DataFrame(carrerasUNAM)
df2.columns = ["Carrera"]
df2.to_excel("OfertaUNAM.xlsx", index=False)
df2

"""#.3 libros"""

pattern = input("Ingresa la palabra o frase a buscar: ")
pdf_path = 'Rebelión en la granja.pdf'
pdf = PdfReader(pdf_path)
pdf_resultado = PdfWriter()
for num_pagina, pagina in enumerate(pdf.pages, start=1):
    texto = pagina.extract_text()
    coincidencias = re.findall(pattern, texto)
    if coincidencias:
        pdf_resultado.add_page(pagina)
        print(f'Página {num_pagina} con coincidencias:')
        print(texto)
pdf_resultado_path = 'resultadoBusqueda.pdf'
with open(pdf_resultado_path, 'wb') as pdf_final:
    pdf_resultado.write(pdf_final)

"""#.4 páginas comerciales

"""

# BEST BUY
best_buy = "https://www.bestbuy.com/site/video-games/retro-gaming/pcmcat1500927006607.c?id=pcmcat1500927006607"
data_best_buy = BeautifulSoup(request.urlopen(request.Request(best_buy, headers=hdr)).read().decode('utf8'), 'html.parser')
productos_divs = data_best_buy.find_all("li",{"class": "sku-item"})
productos = {}
for div in productos_divs:
    productos[div.find('h4').text] = ["".join(re.findall(r'\$\d+\.\d{2}', str(div.find("div",{"data-testid": "customer-price"}))))]
df = pd.DataFrame.from_dict(productos, orient='index', columns=['Precio'])
df.reset_index(inplace=True)
df.rename(columns={'index': 'Producto'}, inplace=True)
df.to_excel('productosBESTBUY.xlsx', index=False)
df

# EBAY
ebay = "https://www.ebay.com/globaldeals"
data = BeautifulSoup(request.urlopen(request.Request(ebay, headers=hdr)).read().decode('utf8'), 'html.parser')
productos_divs = data.find_all("div",{"class": "col"})
productos = {}
for div in productos_divs:
    str_producto = "".join(re.findall(r'\"\>.*\<\/', str(div.find("span",{"itemprop": "name"}))))
    str_producto = re.sub("\<\/", "", str(re.sub("\"\>", "", str(str_producto))))
    productos[str_producto] = ["".join(re.findall(r'\$\d+\.\d{2}', str(div.find("span",{"itemprop": "price"}))))]

df = pd.DataFrame.from_dict(productos, orient='index', columns=['Precio'])
df.reset_index(inplace=True)
df.rename(columns={'index': 'Producto'}, inplace=True)

df.to_excel('productosEBAY.xlsx', index=False)

df

# Amazon
Amazon = "https://www.amazon.com.mx/s?k=rtx&__mk_es_MX=%C3%85M%C3%85%C5%BD%C3%95%C3%91&crid=1W2CGHPA6QWZP&sprefix=rt%2Caps%2C162&ref=nb_sb_noss_2"
data = BeautifulSoup(request.urlopen(request.Request(Amazon, headers=hdr)).read().decode('utf8'), 'html.parser')
productos_divs = data.find_all("div",{"class": "sg-col-4-of-24"})
productos = {}
for div in productos_divs:
    aproducto = re.sub("\<\/", "", str(re.sub("\"\>", "", str("".join(re.findall(r'\"\>.*\<\/', str(div.find("span",{"class":"a-size-base-plus"}))))))))
    productos[aproducto] = ["".join(re.findall(r'\d+', str(div.find("span",{"class": "a-price-whole"}))))]
df = pd.DataFrame.from_dict(productos, orient='index', columns=['Precio'])
df.reset_index(inplace=True)
df.rename(columns={'index': 'Producto'}, inplace=True)
df.to_excel('productosAmazon.xlsx', index=False)
df

# odessalibrerias
odessa = "https://www.odessalibrerias.com.mx/"
data = BeautifulSoup(request.urlopen(request.Request(odessa, headers=hdr)).read().decode('utf8'), 'html.parser')
productos = data.find_all("div",{"class": "product"})
productos1 = {}
for div in productos:
    productos1[div.find('h3').text] = ["".join(div.find("span",{"class": "price"}))]
df = pd.DataFrame.from_dict(productos1, orient='index', columns=['Precio'])
df.reset_index(inplace=True)
df.rename(columns={'index': 'Producto'}, inplace=True)
df.to_excel('productosOdessa.xlsx', index=False)
df